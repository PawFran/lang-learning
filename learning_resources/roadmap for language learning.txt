roadmap for language learning

dodać do ćwiczeń koniugacji perfecti passivi

zaimki są często odmienne - uwzględnić to w kodzie, w bazie i w słowniku!
np. plerusque, pleraque, plerumque

complures źle się scrape'uje (adj pl ale też noun pl)

losować zdania ze słów często mylonych

tempus znajduje dwa razy ? tempora
podobnie panis

adjective anomalous ? singuli - bez neutrum, tylko l. mnoga
singŭli, singulae [adj]
(Fuit moris antiqui eos, qui vel singulorum laudes vel urbium scripserant, aut honoribus aut pecunia ornare)
1. poszczególni, każdy z osobna, jednostki

obsłużyć res gestae - fraza

malum - znajduje więc nie scrape'uje innych opcji

w przypadku III deklinacji pytać też o genre

dodać opcję -s (--sentence) która sprawia że wszystkie słowa, które są scrape'owane mają uzupełniony przykład tego zdania

słowo łacińskie - do niego dobrać słowo polskie - użytkownik może coś wpisać a LLM znaleźć słowa najbardziej pasujące ze słownika - użytkownik wybiera które (może więcej niż jedno ?). może dodać info o części mowy żeby zawęzić wyszukiwanie ?

słowo łacińskie - podać tłumaczenie (wyszukiwarka w trakcie pisania z tłumaczeń dostępnych w słowniku)

słowo łacińskie - podać formę i częśc mowy ?

skróty do opowiedzi na -i na gen sing, ere na inf II/III deklinacji itp.

zrobić wydruk spójników w słowniku

losowanie zdań ze słownika

sprawdzać jak często dane słowa były sprawdzane - trzeba je częściej losować

speech to text ?

przykłady powinny dotyczyć konkretnych tłumaczeń a nie całego słowa (np. mors parci nulli)

scrape z konkretnej strony np. https://www.online-latin-dictionary.com/latin-dictionary-flexion.php?lemma=MEDIUM100

błąd przy poniższym (i tak zamiast genetivu powinby być formy fem i neut - ale nie ma neutrum)
singŭli, singulōrum [adj]
(Leges salutem omnium singulorum saluti anteponunt)
1. pojedynczy, każdy z osobna

słowa, które są najczęściej sprawdzane przez find_or_scrape

multus, multă, multum - sprawdzić w słowniku papierowym

dodać sprawdzanie rodzaju dla rzeczowników w translation_exercise

pytając o słowo łacińskie podawać wszystkie jego tłumaczenia ?

grupować w jakiś sposób słowa, które są podobne ? np. patrzeć i spostrzegać. może chat gpt mógłby to zrobić

już po bazie danych: wyłapywać co było błędem i dopytywać tylko o to (w translation_exercise) - np. tylko supinum od jakiegoś słowa ciągle jest źle, więc nie ma sensu dopytywać o wszystkie formy

servĭo, servīre, servii/servivi, servitum - obsłużyć warianty

wpisać zdanie łacińskie i dostać scrape wszystkich słów i uzupełnione w () to zdanie
podczas screpe'owania wskazywać też jaka to jest forma (i czy na pewno została znaleziona - patrz appetimus)

co jeśli dwie formy perf są poprawne ? np appetii o appetivi

gdyby ściągnąć całe odmiany z LATIN DICTIONARY można by było w ćwieczeniach
deklinacja/koniugacja pytać o dowolne słowa a nie tylko te zapisane w json

scrape - zwracać również formę której się szukało (i info o niej), a nie tylko podstawową

statystyki i graficzne przedstawienia najczęściej popełnianych błędów

sugestie co trzeba przećwiczyć

testy do parsowania - dla wszystkich słów w słowniku zrobić parsing i sprawdzić, czy nagłówki po parsowaniu są takie same jak w słowniku

concido dziala zle - jest niejednoznaczne, bierze tlumaczenie z wersji 2 a supinum z wersji 1. infinitivus ma zły akcent

### vulneratus, vulnerată, vulneratum - nie działa vulneratus 3

dodać pronoun do słownika: quis, quis quid oraz qui quae quod - i wszystkie w ogóle zaimki

dodać skrypt zadający szereg pytań kontrolnych z latin notes

ćwiczenie na gui - wpisać zdanie i system każe wskazać formy i części zdania każdego słowa, np. wybierając z listy

dodać participium do deklinacji ? albo osobne ćwiczenie

obsłużyć en - interjection

-ne enklityka, przyrostek https://pl.wiktionary.org/wiki/-ne

que - enklityka. dodać ?

āio - nieregularny

dissĕro, dissĕrāre [verb] [I]
()
1. dyskutować

podczas nowej sesji pytać najpierw o to, co dotąd było najczęściej źle (powiedzmy ostatnie x razy) a potem wg kolejności
co z tymi, które w trakcie sesji zostały źle ocenione ? może podbijać prawdopodobieństwo o X

cwiczenie na tlumaczenia lat -> pl. slowo lacinskie i kilka mozliwosci tlumaczenia pl. jakie mozliwosci wybrac ?
najpierw losowo, ale potem znajdywac w jakis sposob slowa najczesciej ze soba mylone
inna opcja to pozwolic zaczac wpisywac i dawac podpowiedzi, ale to nie zadziala w terminalu
a może zadziała - https://pymotw.com/2/readline/

analiza odpowiedzi - znalezc najblizsze slowo. dzieki temu bedzie mozna patrzec, jakie slowa sa mylone albo czy pomylka nie jest tylko kwestia literowki

co jeśli dane słowo pl można tłumaczyć na dwa różne obce ? pytać wtedy o oba tłumaczenia

do latin notes dodać losowanie pytania i napisać skrypt do ich losowania

w bazie powinna być forma słowa z akcentami i bez - żeby ułatwić filtrowanie

jeśli jest więcej niż jedno tłumaczenie danego słowa pytać o oba. jak to się ma do filtrowania ?

był błąd w infelix - teraz jest ok. sprawdzic pozostałe czasowniki

jest błąd w cado - supin jest pusty a on odczytuje coś gerundium abl

quis, quis, quid - dodać do słownika i ćwiczeń. w ogóle podsumowanie zaimków.. w declension.json zamiast relative powinno być pronoun relative, albo jeszcze jeden poziom i typ - np. noun, pronoun, participium etc.

baza relacyjna

uporządkować notatki z latin notes.txt

haskell - scraping i parsowanie jsonów na relacyjne csv (chociaż to drugie może być też w pythonie)

dodać bazę do innych ćwiczeń - declension etc. nie ma sensu pytac o rzeczy, ktore sie podaje dobrze

smart sampling jako default, ale opcja na equal sampling

nie da się teraz dobrze  odpowiedzieć na stawać się (factus sum to dwa słowa)
fīo, fieri, factus sum, factum [verb] [anomalous]
()
1. stawać się


ćwiczenie: stopniowanie przymiotników. dodać gradus do LatinAdjective

predykcja - jaka jest szansa że odpowiedź będzie poprawna ? np. regresja logistyczna
użyć do tego, żeby zobaczyć, jak dobre jest smart sampling. użyć do tego, żeby opracować lepsze smart sampling

obsłużyć imiesłowy: LatinParticipium

dodać do bazy session id. sprawdzać potem statystyki - generalnie prawdopodobieństwo poprawnej odpowiedzi w ramach jednej sesji powinno rosnąć

obsłużyć w słowniku zaimki (dodatkowa klasa LatinPronoun):
is, ea, id [pron]
()
1. ten, ta, to

quis, quis, quid [pronoun]
()
1. kto, który

scrapowanie - w przypadku disambiguation powinien próbować każdej opcji dopóki któraś się nie uda

jakieś podsumowanie kiedy używa się przyimków a kiedy nie - np. hospitio accipit

baza danych (csv) do perf and supine exercise

translation exercise: w przypadku czasownikow zaznaczac jakos co zostalo zle podane (np supinum)

tłumaczenie łacińskich słów na polskie - moze wybierac cos z listy, zeby nie musiec wpisywac dokladnie (np. najczesciej mylone slowa) - albo lista rozwijana

implementacja reguł filtrowania:
    np tylko słowa, które w ciągu ostatnich X prób były podane błędnie lub miały mniej niż X prób

bazy danych rowniez do innych cwiczen (declension, conjugation etc.)

print ranking for smart sampling

podczas help w skryptach wypisywać wszystkie możliwe opcje (enum)

po każdym skrypcie wypisywać błędy

translation_exercise - dla pierwszej i drugiej deklinacji dopuscic koncowki zamiast pelnych form

translation exercise - czasem dwa tlumaczenia sa dopuszczalne. pytac wtedy o oba (albo wiecej)

stworzyć model pokazujący zapamiętywanie na podstawie tego, co jest w results.csv

przykład powinien być do tłumaczenia nie do słowa

pytanie o rodzaj rzeczownika w III deklinacji

złe parsowanie (cīvis, civis [noun] [m] [feminine] - powinna być walidacja na ENUMach

find or scrape - dodać opcję -f --force żeby zmusić do scrape'owania nawet jeśli jest w słowniku

nie zawsze pierwsza deklinacja kończy się na are, avi, atum (patrz do, dare, dedi, datum) - więc trzeba zmienić regułę skrótu

podsumowywanie błędów po zakończeniu skryptu

kiedy jedno slowo polskie ma wiecej niz jeden odpowiednik trzeba podac wszystkie

zaimki osobowe

losowanie słów do zdań - być może po polsku (smart, balansować np. czasowniki, przyimki itp.)

rzeczownik/czasownik po lacinie i wypisanie wszystkich mozliwych form, w jakim moze wystepować (deklinacja/koniugacja)

dowolna forma koniugacji / deklinacji - powiedziec jaka to forma

wziecie tylko n slow z najnizszym ratio (oraz nowych - N/A jako pierwsze w sortowaniu)

slowo polskie jako tlumaczenie lacinskiego. jeśli tłumaczen jest wiele trzeba podac wszystkie (liczba moze byc podpowiedziana)

odpytywanie o rozne formy - np slowo polskie ale w supinum

dowolne ze slow ze slownika w dowolnej formie (przez api) i podanie tej formy

znajdywanie duplikatów w słowniku

skrypt find or scrape - po scrape'owaniu jeszcze raz sprawdzenie czy na pewno nie bylo (bo może wpisane forme inna niz podstawowa). mozna wskazac wiecej niz jedno haslo obecne w slowniku

random word powinno losować dane z tej samej bazy co translation ex (w opcji smart)

sprawdzac jakie slowa sa ze soba najczesciej mylone

option to filter only new or not mastered words

option to filter only top X (count, not percentage)

do testow scrapingu dodac: altus, bonus, cogito, inimicus, inter, centum, unus

zrobic wlasna baze dla kilku tysiecy najczestszych slow

uzywajac latin online dict mozna pytac o deklinacje/koniugacje dla dowolnego slowa ze slownika

kazda deklinacje, koniugacje testowac w dwie strony - z podenj formy podawac slowo, ale tez ze slowa wszystkie formy ktore mu odpowiadaja

translation exercise: from latin to polish

podać czasownik i zapytać o jego formę (mood, tense, voice, person, nr)

scrape'ing: usuwanie duplikatów z argumentów wejściowych (albo opcja dodawania zdania)

usuwanie duplikatów z wyników scrape'owania

może przykłady w słowniku powinny być opcjonalne ?

deepl glossary https://www.deepl.com/pl/docs-api/glossaries/list-glossaries/ - could be better than elastic / mongo db

ukryć klucz do API deepl

dodac infinitivus praesentis passivi do conjugation.json

jak zadziala smart sampling w przypadku filtrowania (podzbiory wyrazow) ?

w każdym skrypcie - filtrowanie tylko pewnych części mowy (trzeba tez filtrowac baze)

symulowac przeciwnikow dla RL w grze w zgadywanie slow. tzn. rozne modele pamieci i zadanie dla RL zeby nauczyc sie uzyskiwac jak najwyzsze rezultaty przeciwko nim
jakiekolwiek explainable ai dla takich modeli ? w ten sposob mozna by modelowac pamiec roznych osob

niektóre tłumaczenia nie są unikalne. np et, atque, nec non

test na parsowanie slownika - czy nie ma typu none. albo rzucanie wyjatku kiedy nie uda sie czegos sparsowac. zrobic test automatyczny

walidacja, czy kazde slowo ma przyklad w "()"

skrypt do wypisywania samych slow (podstawowa forma)

skrypt do wypisywania samych znaczen (pierwsze tlumaczenie)

pytac o znaczenie slowa - wystarczy podac jedno, traktujac slowa oddzielone przecinkiem jako osobne, nie troszczac sie o polskie znaki

pytac o forme podstawowa, inf, perf, sup

tracking user's difficulties (profiles, database, tracking previous progress) and personalizing questions
also calculating statistics (how memory user has ? how often one should remind him words which were not asked recently ? performance vs frequency)
github pipeline for running pytest (and mypy) and updating requirements.txt
github packages, docker, pylint https://github.blog/2022-02-02-build-ci-cd-pipeline-github-actions-four-steps/
web app with a few endpoints as a counterparts for runnable scripts ?
"how to use it" should be available in "help" option for all modules
validators for files
track how many times word appeared (and was removed if flag was set). used that info for weighting probabilities
for random words keep track of which were not removed when there was option to do so. with it may be written to csv file
take only recent tries under consideration for specifying distribution

z kazdego slowa brac pierwsze tlumaczenie; podawac je pytac o tlumaczenie na obcu jezyk (z tolerancja dla liter akcentowanych itp.)
wypisywac kilka slow; mozna z nich teraz ukladac zdania
brac tlumaczenie i kazac podac konkretna forme (np. supinum)
