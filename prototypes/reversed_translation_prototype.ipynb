{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "app outline\n",
    "1. random word from latin words\n",
    "2. all translations\n",
    "3. all translation for that word\n",
    "4. input some text\n",
    "5. get 5 most relevant (confidence bigger than X)\n",
    "6. confirm by number or reject (r)\n",
    "7. skip or try again\n",
    "8. ask for clue (example if present)\n",
    "9. save score\n",
    "\n",
    "prototype outline\n",
    "1. get translations\n",
    "2. vectorize them\n",
    "3. input text\n",
    "4. find most relevant synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 982 translations from the database\n",
      "\n",
      "Sample translations:\n",
      "karać\n",
      "winnica\n",
      "patrzeć, widzieć\n",
      "bardzo\n",
      "chwalić\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from environment.setup import engine\n",
    "\n",
    "# Add the parent directory to sys.path to import from database\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from database.db_classes import Translations\n",
    "\n",
    "# Create engine and session\n",
    "# engine = create_engine('sqlite:///path/to/your/database.db')  # Replace with your actual database URL\n",
    "Session = sessionmaker(bind=engine)\n",
    "\n",
    "def get_all_translations():\n",
    "    \"\"\"\n",
    "    Retrieve all translations from the database using the Translations class.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of all translation records from the database\n",
    "    \"\"\"\n",
    "    session = Session()\n",
    "    try:\n",
    "        translations = session.query(Translations).all()\n",
    "        return translations\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving translations: {e}\")\n",
    "        return []\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "translations = get_all_translations()\n",
    "print(f\"Retrieved {len(translations)} translations from the database\")\n",
    "\n",
    "# Display a few sample translations if available\n",
    "if translations:\n",
    "    print(\"\\nSample translations:\")\n",
    "    for translation in translations[:5]: \n",
    "        print(translation.translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created 982 Documents\n",
      "\n",
      "Sample Documents:\n",
      "Content: karać\n",
      "Content: winnica\n",
      "Content: patrzeć, widzieć\n"
     ]
    }
   ],
   "source": [
    "# from langchain.schema import Document\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Convert translations to Documents\n",
    "translation_docs = []\n",
    "for translation in translations:\n",
    "    doc = Document(\n",
    "        page_content=translation.translation\n",
    "    )\n",
    "    translation_docs.append(doc)\n",
    "\n",
    "print(f\"\\nCreated {len(translation_docs)} Documents\")\n",
    "# Display a few sample documents if available\n",
    "if translation_docs:\n",
    "    print(\"\\nSample Documents:\")\n",
    "    for doc in translation_docs[:3]:  # Show first 3 documents\n",
    "        print(f\"Content: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bw/03k6g2hn1hx0ll49lkwmn2jh0000gn/T/ipykernel_6384/4268815290.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "doc_embeddings = embeddings.embed_documents([doc.page_content for doc in translation_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_relevant_documents(query: str, n: int, documents: list, open_AI_embeddings: OpenAIEmbeddings, doc_embeddings: list) -> list:\n",
    "    \"\"\"\n",
    "    Find the N most relevant documents for a given query word using LangChain embeddings and cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The input word to find similar documents for\n",
    "        n (int): Number of relevant documents to return\n",
    "        documents (list): List of Document objects to search through\n",
    "        \n",
    "    Returns:\n",
    "        list: The N most relevant Document objects sorted by similarity\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get embeddings for query and documents\n",
    "    query_embedding = open_AI_embeddings.embed_query(query)\n",
    "    \n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    similarities = []\n",
    "    for i, doc_embedding in enumerate(doc_embeddings):\n",
    "        similarity = np.dot(query_embedding, doc_embedding) / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding))\n",
    "        similarities.append((similarity, i))\n",
    "    \n",
    "    # Sort by similarity and get top N\n",
    "    similarities.sort(reverse=True)\n",
    "    top_n_indices = [idx for _, idx in similarities[:n]]\n",
    "    \n",
    "    # Return the most relevant documents\n",
    "    return [documents[idx] for idx in top_n_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_translations(query: str, n: int = 3) -> list[str]:\n",
    "    relevant_docs = get_relevant_documents(\n",
    "        query, \n",
    "        n=n, \n",
    "        documents=translation_docs, \n",
    "        open_AI_embeddings=embeddings, \n",
    "        doc_embeddings=doc_embeddings\n",
    "        )\n",
    "\n",
    "    return [doc.page_content for doc in relevant_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['krzyk, zgiełk, hałas (ludzki)', 'zamieszanie, wrzawa, zgiełk', 'hańba']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_translations('hałas zgiełk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['widowisko publiczne, igrzyska', 'wojsko', 'wieża', 'świątynia', 'wieniec']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_translations('widowisko', 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
